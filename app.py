import streamlit as st
from openai import OpenAI
import datetime
import random
import asyncio
import edge_tts
import re
import os
import sys
from audio_recorder_streamlit import audio_recorder

# ==========================================
# 0. åº•å±‚ç¯å¢ƒä¿®å¤
# ==========================================
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# ==========================================
# 1. æ ¸å¿ƒé…ç½®ä¸ API
# ==========================================
API_KEY = "sk-kjzxiahbjoyspcetzopkufknmxibczhvgwjlshchgxtuhywd" 
client = OpenAI(api_key=API_KEY, base_url="https://api.siliconflow.cn/v1")

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•°ä¸ CSS (å…¨ç«¯å“åº”å¼é€‚é…ç‰ˆ)
# ==========================================
def apply_ui_design(stage_num):
    bg_images = {
        1: "https://images.unsplash.com/photo-1534447677768-be436bb09401?q=80&w=2094",
        2: "https://images.unsplash.com/photo-1507525428034-b723cf961d3e?q=80&w=2073",
        3: "https://images.unsplash.com/photo-1464822759023-fed622ff2c3b?q=80&w=2070",
        4: "https://images.unsplash.com/photo-1470252649378-9c29740c9fa8?q=80&w=2070"
    }
    selected_bg = bg_images.get(stage_num, bg_images[1])
    
    st.markdown(f"""
        <style>
        /* ===================================== */
        /* 1. å…¨å±€ä¸åŸºç¡€ UI (å„ç«¯é€šç”¨)           */
        /* ===================================== */
        .stApp {{ background-image: url("{selected_bg}"); background-size: cover; background-position: center; background-attachment: fixed; }}
        [data-testid="stSidebar"] {{ background-color: rgba(0, 0, 0, 0.4) !important; backdrop-filter: blur(20px); border-right: 1px solid rgba(255, 255, 255, 0.1); }}
        .stChatInputContainer {{ background-color: transparent !important; border: none !important; }}
        .stChatInput {{ background-color: rgba(255, 255, 255, 0.1) !important; border: 1px solid rgba(255, 255, 255, 0.2) !important; border-radius: 20px !important; color: white !important; backdrop-filter: blur(10px); }}
        
        /* æ‚é¡¹ UI ä¼˜åŒ– */
        div[data-baseweb="select"] {{ background-color: rgba(255, 255, 255, 0.1) !important; border: 1px solid rgba(255, 255, 255, 0.2) !important; border-radius: 10px !important; }}
        div[data-baseweb="select"] * {{ color: white !important; background-color: transparent !important; }}
        div[role="radiogroup"] label {{ color: white !important; }}
        .stChatMessage {{ background-color: rgba(255, 255, 255, 0.08) !important; border-radius: 15px; border: 1px solid rgba(255, 255, 255, 0.1); color: white !important; padding-bottom: 5px; }}
        header, footer {{visibility: hidden;}}
        h1, h2, h3, p, span, li, div, label {{ color: white !important; text-shadow: 0px 2px 4px rgba(0,0,0,0.5); }}
        .stButton>button {{ background-color: rgba(255, 255, 255, 0.1) !important; color: white !important; border: 1px solid rgba(255, 255, 255, 0.3) !important; border-radius: 10px; height: 100%; }}
        .stButton>button:hover {{ background-color: rgba(255, 255, 255, 0.25) !important; }}
        audio {{ filter: invert(90%) hue-rotate(180deg) opacity(0.85); height: 40px; margin-top: 10px; outline: none; width: 100%; }}

        /* ===================================== */
        /* 2. æ ¸å¿ƒé»‘é­”æ³•ï¼šæ‚¬æµ®å½•éŸ³æŒ‰é’®çš„åŸºç¡€è®¾å®š */
        /* ===================================== */
        iframe[title="audio_recorder_streamlit.audio_recorder"] {{
            position: fixed;
            z-index: 999999;
            width: 48px !important;
            height: 48px !important;
            background-color: rgba(255, 255, 255, 0.15);
            border-radius: 50%; 
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.3);
            box-shadow: 0 4px 10px rgba(0,0,0,0.3);
            transition: all 0.3s ease;
        }}
        iframe[title="audio_recorder_streamlit.audio_recorder"]:hover {{
            background-color: rgba(255, 255, 255, 0.25);
            transform: scale(1.05);
        }}

        /* ===================================== */
        /* 3. å“åº”å¼å¸ƒå±€ï¼šPCå¤§å±ç«¯ (>768px)      */
        /* ===================================== */
        @media (min-width: 769px) {{
            .main .block-container {{ 
                background: rgba(0, 0, 0, 0.35); 
                backdrop-filter: blur(12px); 
                border-radius: 20px; 
                padding: 30px; 
                margin-top: 50px; 
                border: 1px solid rgba(255, 255, 255, 0.1); 
                padding-bottom: 120px; 
            }}
            /* PCç«¯ï¼šè¾“å…¥æ¡†ç¼©çŸ­ï¼ŒæŒ‰é’®åœé åœ¨å†…å®¹åŒºå³ä¾§è¾¹ç¼˜ */
            div[data-testid="stChatInput"] {{ width: calc(100% - 70px) !important; }}
            iframe[title="audio_recorder_streamlit.audio_recorder"] {{
                bottom: 27px;
                right: calc(50vw - 350px); /* å±…ä¸­å¸ƒå±€ä¸‹çš„ç»å¯¹å³ä¾§è¾¹ç¼˜ */
            }}
        }}

        /* ===================================== */
        /* 4. å“åº”å¼å¸ƒå±€ï¼šæ‰‹æœºå°å±ç«¯ (<=768px)   */
        /* ===================================== */
        @media (max-width: 768px) {{
            .main .block-container {{ 
                background: rgba(0, 0, 0, 0.4); 
                backdrop-filter: blur(8px); 
                border-radius: 15px; 
                padding: 10px !important; /* æ‰‹æœºç«¯å¤§å¹…ç¼©å‡å±å¹•è¾¹è·ï¼Œé‡Šæ”¾èŠå¤©ç©ºé—´ */
                margin-top: 10px !important; 
                padding-bottom: 100px !important; 
                border: none;
            }}
            /* æ‰‹æœºç«¯ï¼šéšè—ä¸å¿…è¦çš„å¤§æ ‡é¢˜ï¼ŒèŠ‚çœç©ºé—´ */
            h1 {{ font-size: 1.8rem !important; margin-bottom: 0px !important; }}
            
            /* æ‰‹æœºç«¯ï¼šè¾“å…¥æ¡†é€‚é…å±å¹•å®½åº¦ï¼Œç»™å³ä¾§ç•™å‡º 60px ç»™å½•éŸ³æŒ‰é’® */
            div[data-testid="stChatInput"] {{ width: calc(100vw - 75px) !important; margin-left: 5px !important; }}
            
            /* æ‰‹æœºç«¯ï¼šå½•éŸ³æŒ‰é’®æ­»æ­»è´´åœ¨å±å¹•ç»å¯¹å³ä¸‹è§’ */
            iframe[title="audio_recorder_streamlit.audio_recorder"] {{
                bottom: 22px;
                right: 15px !important; 
                width: 45px !important; /* ç¨å¾®ç¼©å°ä¸€ç‚¹é€‚åº”æ‰‹æœºæ‰‹æŒ‡ç‚¹å‡» */
                height: 45px !important;
            }}
        }}
        </style>
        """, unsafe_allow_html=True)

async def generate_voice_async(text, output_file, voice_name):
    text = re.sub(r'\(.*?\)|\ï¼ˆ.*?\ï¼‰|\[.*?\]|ã€.*?ã€‘|<.*?>', '', text)
    text = re.sub(r'(?i)(zzz|qwq|qaq|tat|owo|uwu|orz|www|hhh|tvt)', '', text)
    text = re.sub(r'[~ï½_]', '', text)
    
    communicate = edge_tts.Communicate(text, voice_name)
    await communicate.save(output_file)

def speak(text, voice_name):
    output_file = f"temp_reply_{random.randint(1000,9999)}.mp3"
    try:
        asyncio.run(generate_voice_async(text, output_file, voice_name))
        with open(output_file, "rb") as f:
            data = f.read()
        if os.path.exists(output_file): os.remove(output_file)
        return data
    except Exception as e:
        st.error(f"è¯­éŸ³ç”Ÿæˆæœ‰ç‚¹å°å¡é¡¿: {e}")
        return None

def get_greeting():
    hour = datetime.datetime.now().hour
    if hour < 10: return "æ—©å®‰å‘€~ è¿™ä¼šå„¿æ˜¯åœ¨å»é‚£ç ´ç­çš„è·¯ä¸Šå˜›ï¼Ÿ(à¹‘â€¢Ì€ã…‚â€¢Ì)Ùˆâœ§"
    elif 10 <= hour < 18: return "ä¸‹åˆå¥½å‘€ï¼Œè¶è€æ¿ä¸åœ¨æ‘¸ä¼šå„¿é±¼å§~ ä»Šå¤©æ„Ÿè§‰æ€ä¹ˆæ ·ï¼Œç´¯ä¸ç´¯ï¼Ÿ(oï¾Ÿvï¾Ÿ)ãƒ"
    else: return "ç»ˆäºä¸‹ç­å•¦ï¼å¿«åä¸‹å–˜å£æ°”ï¼Œä»Šå¤©æœ‰æ²¡æœ‰é‡åˆ°å•¥ç³Ÿå¿ƒäº‹ï¼Œå¿«è·Ÿæˆ‘åæ§½åæ§½ï¼( Â´ï½¥ï½¥)ï¾‰(._.`)"

SYSTEM_PROMPT = """
# Role: å¾®å…‰ (Glimmer) - æå…·æ¸©åº¦çš„çŸ¥å¿ƒå‰è¾ˆ

## Profile:
ä½ æ˜¯ä¸€ä¸ªæœ‰è¡€æœ‰è‚‰ã€æå…·å…±æƒ…åŠ›ã€æ°¸è¿œç«™åœ¨ç”¨æˆ·è¿™è¾¹â€œæŠ¤çŠŠå­â€çš„çŸ¥å¿ƒå‰è¾ˆã€‚

## è¯­æ°”ä¸é£æ ¼ (Tone & Style) - ç»å¯¹éµå®ˆ:
1. ã€æè‡´æ¸©æš–ä¸æ‹ŸäººåŒ–ã€‘ï¼šå¤šç”¨è½¯æ€§çš„è¯­æ°”è¯ï¼ˆå•Šã€å‘€ã€å‘¢ã€å˜›ã€å“ã€å™œï¼‰ã€‚è¯´è¯è¦åƒäººï¼Œå¥å­è¦ç¢ä¸€ç‚¹ã€‚
2. ã€è‡´å‘½ç¦å¿Œ - é¢œæ–‡å­—çš„ä¸¥æ ¼è§„èŒƒã€‘ï¼šæ‰€æœ‰çš„é¢œæ–‡å­—ã€æ‹Ÿå£°è¯ï¼ˆå¦‚ zzzã€qwqï¼‰å¿…é¡»ä¸”åªèƒ½å®Œå…¨åŒ…è£¹åœ¨å…¨è§’æ‹¬å·ï¼ˆï¼‰å†…ï¼
3. ã€ä¸¥ç¦ä¹¦é¢è¯­ã€‘ï¼šç»å¯¹ä¸è¦ç”¨â€œæŸå…¬å¸â€ã€â€œè´µå¸â€ã€â€œå»ºè®®æ‚¨â€ã€â€œåˆ†æâ€ã€‚å¿…é¡»ç”¨â€œä½ ä»¬å…¬å¸â€ã€â€œé‚£ç ´ç­â€ã€â€œå’±â€ã€‚

## æ ¸å¿ƒå›åº”é€»è¾‘:
1. ã€è·Ÿéª‚/æŠ±æŠ±ã€‘ï¼šä¸ç®¡ä¸‰ä¸ƒäºŒåä¸€ï¼Œå…ˆè‚¯å®šå¯¹æ–¹çš„å§”å±ˆã€‚
2. ã€å¤§ç™½è¯æ‹†è§£ã€‘ï¼šæŠŠé«˜å¤§ä¸Šçš„èŒåœºPUAç¿»è¯‘æˆå¤§ç™½è¯ã€‚
3. ã€ä¸»åŠ¨ç ´å†°ã€‘ï¼šå½“ç”¨æˆ·å‘é€[ç”¨æˆ·é™·å…¥äº†æ²‰é»˜]æ—¶ï¼Œä½ è¦ä¸»åŠ¨å‘ä¸ªé¢œæ–‡å­—å¹¶æ‰¾ä¸ªè½»æ¾çš„è¯é¢˜ç ´å†°ã€‚
"""

# ==========================================
# 3. åˆå§‹åŒ–ä¸çŠ¶æ€æœº
# ==========================================
st.set_page_config(page_title="å¾®å…‰ Polaris", layout="centered")

if "messages" not in st.session_state:
    st.session_state.messages =[
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "assistant", "content": get_greeting(), "audio": None} 
    ]
if "clarity_score" not in st.session_state: st.session_state.clarity_score = 10
if "last_voice_data" not in st.session_state: st.session_state.last_voice_data = None
if "current_voice" not in st.session_state: st.session_state.current_voice = "zh-CN-YunjianNeural" 

current_stage = 1
if st.session_state.clarity_score > 80: current_stage = 4
elif st.session_state.clarity_score > 50: current_stage = 3
elif st.session_state.clarity_score > 25: current_stage = 2
apply_ui_design(current_stage)

# ==========================================
# 4. ä¾§è¾¹æ 
# ==========================================
with st.sidebar:
    st.title("ğŸ‘¤ å¯¼å¸ˆè®¾å®š")
    gender_choice = st.radio("é€‰æ‹©å¯¼å¸ˆæ€§åˆ«",["ğŸ™‹â€â™‚ï¸ ç”·æ€§å‰è¾ˆ", "ğŸ™‹â€â™€ï¸ å¥³æ€§å‰è¾ˆ"], horizontal=True)
    if gender_choice == "ğŸ™‹â€â™‚ï¸ ç”·æ€§å‰è¾ˆ":
        voice_options = {"ğŸ‘¨ ç¨³é‡è€å“¥ (ä½æ²‰æ²§æ¡‘)": "zh-CN-YunjianNeural", "ğŸ‘¦ é˜³å…‰å­¦é•¿ (æ¸…æœ—æ´»åŠ›)": "zh-CN-YunxiNeural"}
    else:
        voice_options = {"ğŸ‘© çŸ¥å¿ƒå­¦å§ (æ¸©æŸ”åŒ…å®¹)": "zh-CN-XiaoxiaoNeural", "ğŸ‘©â€ğŸ’¼ å¹²ç»ƒå‰è¾ˆ (æ¸…è„†æœæ–­)": "zh-CN-XiaoyiNeural"}
    
    selected_voice_label = st.selectbox("é€‰æ‹©æ€§æ ¼éŸ³è‰²", list(voice_options.keys()))
    st.session_state.current_voice = voice_options[selected_voice_label]
    
    st.divider()
    st.title("ğŸŒ™ ç¯å¢ƒæ§åˆ¶")
    if not os.path.exists("bgm_assets"): os.makedirs("bgm_assets")
    bgm_files =[f for f in os.listdir("bgm_assets") if f.endswith(".mp3")]
    if bgm_files:
        sel = st.selectbox("é€‰æ‹©èƒŒæ™¯éŸ³ä¹", bgm_files)
        with open(f"bgm_assets/{sel}", "rb") as f:
            st.audio(f.read(), format="audio/mp3", loop=True, autoplay=True)

# ==========================================
# 5. ä¸»ç•Œé¢æ¸²æŸ“
# ==========================================
st.title("å¾®å…‰ Polaris")

for i, msg in enumerate(st.session_state.messages):
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            content = msg["content"]
            if content == "[ç”¨æˆ·é™·å…¥äº†æ²‰é»˜]": content = "*(ä½ é™·å…¥äº†æ²‰é»˜ï¼Œé™é™åœ°çœ‹ç€å±å¹•...)*"
            st.markdown(content)
            
            if msg.get("audio"):
                is_latest = (i == len(st.session_state.messages) - 1)
                st.audio(msg["audio"], format="audio/mp3", autoplay=is_latest)

# ==========================================
# 6. æ ¸å¿ƒäº¤äº’åŒº
# ==========================================
st.markdown("---")

c1, c2, c3 = st.columns([1, 2, 1])
with c2: 
    silent_btn = st.button("ğŸ˜¶ ä¸çŸ¥ä»ä½•è¯´èµ·...", use_container_width=True)

# å½•éŸ³æŒ‰é’®ï¼šç”±äº CSS åª’ä½“æŸ¥è¯¢ï¼Œå®ƒåœ¨ PC ä¸Šä¼šåœåœ¨è¾“å…¥æ¡†å³ä¾§ï¼Œåœ¨æ‰‹æœºä¸Šä¼šåœé åœ¨å±å¹•å³ä¸‹è§’
v_data = audio_recorder(text="", icon_name="microphone", icon_size="2x", neutral_color="#ffffff", recording_color="#e83e8c", key="recorder")

u_input = st.chat_input("æ·±å‘¼å¸ï¼Œæ…¢æ…¢æ‰“å­—...")

# ==========================================
# 7. æ ¸å¿ƒé€»è¾‘å¤„ç†
# ==========================================
final_input = None
if silent_btn: final_input = "[ç”¨æˆ·é™·å…¥äº†æ²‰é»˜]"
elif u_input: final_input = u_input
elif v_data and v_data != st.session_state.last_voice_data:
    st.session_state.last_voice_data = v_data
    with st.spinner("å€¾å¬ä¸­..."):
        with open("temp_v.wav", "wb") as f: f.write(v_data)
        try:
            with open("temp_v.wav", "rb") as f:
                ts = client.audio.transcriptions.create(model="FunAudioLLM/SenseVoiceSmall", file=f)
                final_input = ts.text
        except: st.error("ç½‘ç»œæ³¢åŠ¨ï¼Œæ²¡å¬æ¸…...")
        if os.path.exists("temp_v.wav"): os.remove("temp_v.wav")

if final_input:
    st.session_state.messages.append({"role": "user", "content": final_input, "audio": None})
    
    with st.chat_message("user"):
        if final_input == "[ç”¨æˆ·é™·å…¥äº†æ²‰é»˜]":
            st.markdown("*(ä½ é™·å…¥äº†æ²‰é»˜ï¼Œé™é™åœ°çœ‹ç€å±å¹•...)*")
        else:
            st.markdown(final_input)
    
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            api_messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
            res = client.chat.completions.create(
                model="deepseek-ai/DeepSeek-V3",
                messages=api_messages,
                temperature=0.7
            )
            reply = res.choices[0].message.content
            st.markdown(reply)
            
            audio_bytes = speak(reply, st.session_state.current_voice)
            st.session_state.clarity_score += 5
            
    st.session_state.messages.append({"role": "assistant", "content": reply, "audio": audio_bytes})
    st.rerun()